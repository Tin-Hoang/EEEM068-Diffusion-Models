# Model configuration
model: lc_unet_5_vqvae
run_name: attribute_lcunet5vqvae_celebamask_2700train_infonce

# Training configuration
image_size: 256
train_batch_size: 32
eval_batch_size: 16
num_epochs: 2000
learning_rate: 2e-4
weight_decay: 1e-2
lr_warmup_steps: 8400  # Updated to be 5% of total training steps (84 batches * 2000 epochs * 0.05)
gradient_accumulation_steps: 1
seed: 42
mixed_precision: "no"

# Save and logging configuration
save_image_epochs: 50
save_model_epochs: 50
root_output_dir: /scratch/group_5/diffusion_checkpoints

# Dataset configuration
train_dir: data/CelebA-HQ-split/train_2700
val_dir: null
val_n_samples: null
dataset_name: celebamask_hq_256_2700train
num_workers: 4

# Diffusion configuration
num_train_timesteps: 1000
scheduler_type: ddpm
use_embedding_loss: true
embedding_loss_lambda: 1.0

# WandB configuration
use_wandb: true
wandb_project: EEEM068_Diffusion_Models
wandb_entity: tin-hoang

# Model architecture configuration
use_ema: false
use_scale_shift_norm: false

# Conditional generation configuration
is_conditional: true
attribute_file: data/CelebA-HQ-split/CelebAMask-HQ-attribute-anno.txt
num_attributes: 40
grid_attribute_indices: [35]  # Wearing Hat
grid_num_samples: 16
grid_sample_random_remaining_indices: true
