# Model configuration
model: unet_notebook
run_name: unet2d_ddpm2000_2000epoch_lr2e-4

# Training configuration
image_size: 128
train_batch_size: 16
eval_batch_size: 16
num_epochs: 2000
learning_rate: 2e-4
weight_decay: 1e-2
lr_warmup_steps: 2000
gradient_accumulation_steps: 1
mixed_precision: "no"

# Save and logging configuration
save_image_epochs: 50
save_model_epochs: 50
root_output_dir: /scratch/group_5/diffusion_checkpoints

# Dataset configuration
train_dir: data/celeba_hq_split/train
val_dir: data/celeba_hq_split/test
val_n_samples: 100
dataset_name: celeba_hq_128_2700train
num_workers: 4

# Diffusion configuration
num_train_timesteps: 2000
scheduler_type: ddpm

# WandB configuration
use_wandb: true
wandb_project: EEEM068_Diffusion_Models
wandb_entity: tin-hoang

# Model architecture configuration
use_ema: false
use_scale_shift_norm: false
is_conditional: false

